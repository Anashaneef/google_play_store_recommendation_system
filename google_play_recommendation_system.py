# -*- coding: utf-8 -*-
"""Copy of Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nC-66LY-RerPbm7hIY1KhY5H6FHR6Odn

Nama = Anas Fikri Hanif\
SIB ID = M183X0321

#**Import Library**
"""

# Commented out IPython magic to ensure Python compatibility.
# Data loading and data analysis
import numpy as np
import pandas as pd
import zipfile
from google.colab import files

# Data visualization
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
plt.style.use('seaborn')

# Data preprocessing
from sklearn.preprocessing import MinMaxScaler

# Modeling
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""#**Preparing Dataset From Kaggle**"""

# Install kaggle 
!pip install -q kaggle

# Token API
uploaded = files.upload()

# Receive dataset config
!chmod 600 /content/kaggle.json

# Download dataset
! KAGGLE_CONFIG_DIR=/content/ kaggle datasets download -d lava18/google-play-store-apps

# extract dataset
local_zip = '/content/google-play-store-apps.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""#**Dataset Information**"""

ps = pd.read_csv('/content/googleplaystore.csv')
ps.head(5)

# Rename some columns name
ps.rename(columns=({'Content Rating':'Content_Rating', 'Last Updated':'Last_Updated', 'Current Ver':'Current_Ver', 'Android Ver':'Android_Ver'}), inplace=True)
ps.head(5)

print(f'Data consist of {ps.shape[1]} columns')
print(f'Each column consists of {ps.shape[0]} records')

print('This is a list of categories: ', ps.Category.unique())

print('This is a list of types: ', ps.Type.unique())

print('This is a list of content ratings: ', ps.Content_Rating.unique())

print('This is a list of genres: ', ps.Genres.unique())

"""#**Exploratory Data Analysis**

**Variabel-variabel yang Ada dalam Dataset**

* App : Nama Aplikasi
* Category : Jenis atau kategori yang dimiliki aplikasi
* Rating : Rata-rata penilaian yang diberikan oleh user
* Reviews : Jumlah komentar yang diberikan oleh user
* Size : Ukuran aplikasi
* Installs : Jumlah download/install aplikasi
* Type : Tipe aplikasi apakah gratis atau berbayar
* Price : Harga aplikasi ketika user ingin mendownloadnya
* Content_Rating : Kepada siapa aplikasi diperuntukkan
* Genres : Genre/tipe yang dimiliki oleh aplikasi
* Last_Updated : Waktu terakhir kali aplikasi diupdate
* Current_Ver : Versi yang dimiliki aplikasi saat ini
* Andriod_Ver : Versi minimal Android untuk bisa menjalankan aplikasi

##**Handling Missing Value**
"""

ps.info()

"""Pengecekan data null"""

ps.isnull().sum()

print('Jumlah data yang null adalah ', ps.isnull().sum().sum(), ' records')

"""Berdasarkan analisis, jumlah data null terbanyak ada pada kolom Rating. Oleh karena itu kita perlu fokus pada kolom Rating terlebih dahulu

**Analysis Rating Data**
"""

ps[['Rating']].describe()

# Pembuatan plot untuk kolom rating
sns.histplot(x=ps['Rating'])
plt.show()

"""Melihat persebaran data dan juga visualisasi di atas menunjukkan kejanggalan. Rating di Play Store seharusnya memiliki nilai maksimal 5, sementara di data kita terdapat sebuah aplikasi yang memiliki Rating 19"""

# Cek aplikasi dengan rating yang lebih dari 5
ps[ps['Rating'] > 5]

"""Ternyata hanya ada satu aplikasi yang memiliki rating di atas 5. Karena hannya ada satu data, maka menghapus data ini seharusnya tidak akan memberikan dampak berarti pada pemodelan kita nanti"""

outlier_data = ps[ps['App'] == 'Life Made WI-Fi Touchscreen Photo Frame'].index
ps.drop(outlier_data, inplace=True)

# Cek kembali aplikasi dengan rating yang lebih dari 5
ps[ps['Rating'] > 5]

ps[['Rating']].describe()

"""Nilai Rating yang lebih dari 5 telah dibersihkan. Sekarang kita akan mengisi nilai null pada rating berdasarkan rata-rata review yang diberikan oleh user pada aplikasi dengan rating tertentu"""

# Melihat Tipe Data variable Rating dan Reviews
print('Tipe data kolom rating adalah ', ps['Rating'].dtype)
print('Tipe data kolom review adalah ', ps['Reviews'].dtype)

# Mengubah tipe data kolom review mwnjadi numeric
ps['Reviews'] = pd.to_numeric(ps['Reviews'])
print('Tipe data kolom review adalah ', ps['Reviews'].dtype)

# Review pada App rating < 1
r1 = ps['Reviews'][ps['Rating'] <=1 ].mean()
print('Rata-rata review pada aplikasi dengan rating <1 adalah: ', r1)

# Review pada App rating > 1 dan <=2
r2 = ps['Reviews'][(ps['Rating'] >1) & (ps['Rating'] <=2) ].mean()
print('Rata-rata review pada aplikasi dengan rating >1 dan <=2 adalah: ', r2)

# Review pada App rating > 2 dan <=3
r3 = ps['Reviews'][(ps['Rating'] >2) & (ps['Rating'] <=3) ].mean()
print('Rata-rata review pada aplikasi dengan rating >2 dan <=3 adalah: ', r3)

# Review pada App rating > 3 dan <=4
r4 = ps['Reviews'][(ps['Rating'] >3) & (ps['Rating'] <=4) ].mean()
print('Rata-rata review pada aplikasi dengan rating >3 dan <=4 adalah: ', r4)

# Review pada App rating < 1
r5 = ps['Reviews'][ps['Rating'] >4 ].mean()
print('Rata-rata review pada aplikasi dengan rating >4 adalah: ', r5)

# Cek data dengan rating null
rating_null = ps[ps['Rating'].isnull()]
rating_null.describe()

"""Karena review tertinggi pada data dengan rating null hanya 3248, maka rating aplikasi dengan nilai null seharusnya tidak lebih dari 3. Oleh karena itu kita akan memberikan rating 2 pada semua rating yang bernilai null"""

ps['Rating'].fillna(2,inplace=True)
print('Jumlah rating dengan nilai null sekarang ada: ', ps['Rating'].isnull().sum())

"""Menghapus data null pada kolom 'Type', 'Content_Rating', 'Current_Ver', dan 'Android_Ver'"""

ps.dropna(how='any',inplace=True)

ps.isnull().sum()

ps.shape

"""Setelah selesai dengan data Null. Sekarang data kita berjumlah 13 kolom, dan masing-masing kolom memiliki 10829 record

##**Data Preprocessing**

**Drop Unused Columns**

Di bagian ini kita akan menghapus kolom-kolom yang tidak diperlukan yaitu kolom 'Last_Updated' dan 'Current_Ver'. Sementara kolom 'Genre' juga akan kita hapus karena kita sudah memiliki kolom 'Category' sehingga kita akan fokus ke sana
"""

ps.drop(['Last_Updated', 'Current_Ver', 'Genres'], inplace=True, axis=1)
ps.head(5)

"""**Category Column**"""

plt.figure(figsize=(15,15))
sns.countplot(y=ps['Category'])
plt.show()

"""Kolom Category memiliki informasi cukup lengkap di mana Category Family memiliki jumlah terbesar di antara semua Category

**Size Column**

Menghilangkan imbuhan M dan k di akhir Size serta mengkonversi tipe data Size menjadi numeric
"""

m_size = ps['Size'][ps['Size'].str.contains('M')]

# Menghapus imbuhan M
m_size = m_size.str.replace('M', '')

# Konversi menjadi numeric
m_size = pd.to_numeric(m_size)

print('Tipe data dari m_size adalah ', m_size.dtype)
print('Jumlah data m_size ada ', m_size.shape[0])

k_size = ps['Size'][ps['Size'].str.contains('k')]

# Menghapus imbuhan k
k_size = k_size.str.replace('k', '')

# Konversi menjadi numeric
k_size = pd.to_numeric(k_size)

print('Tipe data dari k_size adalah ', k_size.dtype)
print('Jumlah data k_size ada ', k_size.shape[0])

# Konversi kb ke Mb
# 1kb = 0.001Mb
k_size = k_size * 0.001

"""Size yang bernilai 'Varies with Device' diganti dengan nilai -1 agar menjadi numerik"""

varies = ps['Size'][ps['Size'] == 'Varies with device']
varies.replace('Varies with device',-1,inplace=True)

ps['Size'].shape

Size = [None for i in range(10829)]

# Membuat index
def index_size(data):
    for index in data.index:
        try:
            Size[index] = data.loc[index]
        except:
            print(index)

index_size(m_size)
index_size(k_size)
index_size(varies)

ps['Size'] = Size
ps.head()

"""**Installs Column**

Mengganti kolom Installs ke tipe numerik dan menghapus tanda +
"""

ps['Installs'].dtype

ps['Installs'] = pd.to_numeric(ps['Installs'].str.replace(r'\D+','',regex=True))
ps['Installs'].dtype

"""**Type Column**

Melihat persebaran aplikasi gratis dan berbayar
"""

ps['Type'].value_counts().plot(kind='pie')
plt.show()

ps['Type'].value_counts()

"""**Price Column**

Memastikan Price bertipe numerik dan menghapus tanda $
"""

ps['Price'].value_counts()

ps['Price'] = ps['Price'].str.replace(r'\$','',regex=True)

ps['Price'] = pd.to_numeric(ps['Price'])

"""**Content_Rating Column**"""

ps['Content_Rating'].value_counts()

"""Karena rating 'Adults only 18+' hanya berjumlah 3 maka kita akan menggabungkannya ke rating 'Mature 17+'. Rating 'Unrated' juga akan kita gabungkan ke konten 'Everyone'"""

ps['Content_Rating'] = ps['Content_Rating'].replace(['Adults only 18+', 'Unrated'], ['Mature 17+', 'Everyone'])

# Plot Content_Rating
ps['Content_Rating'].value_counts().plot(kind='pie')
plt.show()

"""**Android_Ver Column**"""

plt.figure(figsize=(10,10))
sns.countplot(y=ps['Android_Ver'])
plt.xscale('symlog')
plt.title("Android Versions Frequency")
plt.show()

"""Karena persebaran data terlihat kurang rapi, maka untuk versi dengan jumlah aplikasi < 100 akan digabungkan menjadi satu dalam 'Other Version'"""

versions = ps['Android_Ver'].value_counts()

versions[versions<=100].sum()

other = versions[versions<=100].keys()
other

ps['Android_Ver'].replace(other,['Other Versions' for i in range(19)], inplace=True)

plt.figure(figsize=(10,10))
sns.countplot(y=ps['Android_Ver'])
plt.xscale('symlog')
plt.title("Android Versions Frequency")
plt.show()

"""Sekarang persebaran data terlihat lebih rapi"""

ps.head()

"""Mengecek apakah terdapat null"""

ps.isnull().sum()

"""Ternyata kolom size memiliki 12 nilai null. Kita akan menghapus kolom-kolom tersebut"""

ps.dropna(how='any',inplace=True)

ps.isnull().sum()

"""**Clean App Duplicates Name**

Di bagian ini kita akan menghapus aplikasi-aplikasi yang memiliki nama yang sama
"""

ps.drop_duplicates(subset='App',inplace=True)

"""##**Modelling**"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data Category
tf.fit(ps['Category']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(ps['Category']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=ps.App
).sample(22, axis=1).sample(10, axis=0)

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=ps['App'], columns=ps['App'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

def app_recom(app_name, similarity_data=cosine_sim_df, items=ps[['App', 'Category', 'Type', 'Content_Rating', 'Rating']], k=5):

    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,app_name].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(app_name, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

ps[ps['App'] == 'Sketch - Draw & Paint']

app_recom('Sketch - Draw & Paint')

ps[ps['App'] == 'Online Girls Chat']

app_recom('Online Girls Chat')

ps[ps['App'] == 'Mini for Facebook lite']

app_recom('Mini for Facebook lite')

"""Dari rekomendasi-rekomendasi di atas, sistem yang kita buat sudah sangat baik dengan memberikan rekomendasi aplikasi-aplikasi yang memiliki 'Category' yang sama"""